{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c974bd-1bfc-4be6-a4d5-ab28a819b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imgaug.augmenters as iaa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import tensorflow.keras.layers as layers\n",
    "from keras.models import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a39de0e-1363-4342-80e1-f535a22cef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_H = 512\n",
    "IMG_W = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9f4a2-9018-4ef2-b67f-64a5531563ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, split=0.1):\n",
    "    \"\"\" Loading the images and masks \"\"\"\n",
    "    X = sorted(glob(os.path.join(path, \"images\", \"*\")))\n",
    "    Y = sorted(glob(os.path.join(path, \"masks\", \"*\")))\n",
    "\n",
    "    \"\"\" Spliting the data into training and testing \"\"\"\n",
    "    split_size = int(len(X) * split)\n",
    "\n",
    "    train_x, valid_x = train_test_split(X, test_size=split_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(Y, test_size=split_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (IMG_W, IMG_H))\n",
    "    image = image / 255.0\n",
    "    image = image.astype(np.float32)\n",
    "    return image\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (IMG_W, IMG_H))\n",
    "    mask = mask / 255.0\n",
    "    mask = mask.astype(np.float32)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return mask\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([IMG_H, IMG_W, 3])\n",
    "    y.set_shape([IMG_H, IMG_W, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch=2):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    ds = ds.map(tf_parse).batch(batch).prefetch(10)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ba94e-eaa1-4ba3-9535-94f4d3e24a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, kernelsize, filters, dropout, batchnorm=False):\n",
    "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(x)\n",
    "    if batchnorm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "    if dropout > 0:\n",
    "        conv = layers.Dropout(dropout)(conv)\n",
    "    conv = layers.Conv2D(filters, (kernelsize, kernelsize), kernel_initializer='he_normal', padding=\"same\")(conv)\n",
    "    if batchnorm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "    return conv\n",
    "\n",
    "def encoder_block(x, num_filters, dropout, batchnorm):\n",
    "    x = conv_block(x, kernelsize=3, filters=num_filters, dropout=dropout, batchnorm=batchnorm)\n",
    "    x = conv_block(x, kernelsize=3, filters=num_filters, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    p = layers.MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def unet3plus(input_shape, num_classes=1, dropout=0.3, batchnorm=True):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    inputs = layers.Input(input_shape, name=\"input_layer\")\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    e1, p1 = encoder_block(inputs, 64, dropout=dropout, batchnorm=batchnorm)\n",
    "    e2, p2 = encoder_block(p1, 128, dropout=dropout, batchnorm=batchnorm)\n",
    "    e3, p3 = encoder_block(p2, 256, dropout=dropout, batchnorm=batchnorm)\n",
    "    e4, p4 = encoder_block(p3, 512, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    \"\"\" Bottleneck \"\"\"\n",
    "    e5 = conv_block(p4, kernelsize=3, filters=1024, dropout=dropout, batchnorm=batchnorm)\n",
    "    e5 = conv_block(e5, kernelsize=3, filters=1024, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    \"\"\" Decoder 4 \"\"\"\n",
    "    e1_d4 = layers.MaxPool2D((8, 8))(e1)\n",
    "    e1_d4 = conv_block(e1_d4, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    e2_d4 = layers.MaxPool2D((4, 4))(e2)\n",
    "    e2_d4 = conv_block(e2_d4, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    e3_d4 = layers.MaxPool2D((2, 2))(e3)\n",
    "    e3_d4 = conv_block(e3_d4, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    e4_d4 = conv_block(e4, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    e5_d4 = layers.UpSampling2D((2, 2), interpolation=\"bilinear\")(e5)\n",
    "    e5_d4 = conv_block(e5_d4, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    d4 = layers.Concatenate()([e1_d4, e2_d4, e3_d4, e4_d4, e5_d4])\n",
    "    d4 = conv_block(d4, kernelsize=3, filters=64*5, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    \"\"\" Decoder 3 \"\"\"\n",
    "    e1_d3 = layers.MaxPool2D((4, 4))(e1)\n",
    "    e1_d3 = conv_block(e1_d3, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    e2_d3 = layers.MaxPool2D((2, 2))(e2)\n",
    "    e2_d3 = conv_block(e2_d3, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    e3_d3 = conv_block(e3, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    d4_d3 = layers.UpSampling2D((2, 2), interpolation=\"bilinear\")(d4)\n",
    "    d4_d3 = conv_block(d4_d3, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    e5_d3 = layers.UpSampling2D((4, 4), interpolation=\"bilinear\")(e5)\n",
    "    e5_d3 = conv_block(e5_d3, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    d3 = layers.Concatenate()([e1_d3, e2_d3, e3_d3, d4_d3, e5_d3])\n",
    "    d3 = conv_block(d3, kernelsize=3, filters=64*5, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    \"\"\" Decoder 2 \"\"\"\n",
    "    e1_d2 = layers.MaxPool2D((2, 2))(e1)\n",
    "    e1_d2 = conv_block(e1_d2, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    e2_d2 = conv_block(e2, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    d3_d2 = layers.UpSampling2D((2, 2), interpolation=\"bilinear\")(d3)\n",
    "    d3_d2 = conv_block(d3_d2, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    d4_d2 = layers.UpSampling2D((4, 4), interpolation=\"bilinear\")(d4)\n",
    "    d4_d2 = conv_block(d4_d2, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    e5_d2 = layers.UpSampling2D((8, 8), interpolation=\"bilinear\")(e5)\n",
    "    e5_d2 = conv_block(e5_d2, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    d2 = layers.Concatenate()([e1_d2, e2_d2, d3_d2, d4_d2, e5_d2])\n",
    "    d2 = conv_block(d2, kernelsize=3, filters=64*5, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    \"\"\" Decoder 1 \"\"\"\n",
    "    e1_d1 = conv_block(e1, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    d2_d1 = layers.UpSampling2D((2, 2), interpolation=\"bilinear\")(d2)\n",
    "    d2_d1 = conv_block(d2_d1, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    d3_d1 = layers.UpSampling2D((4, 4), interpolation=\"bilinear\")(d3)\n",
    "    d3_d1 = conv_block(d3_d1, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    d4_d1 = layers.UpSampling2D((8, 8), interpolation=\"bilinear\")(d4)\n",
    "    d4_d1 = conv_block(d4_d1, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    e5_d1 = layers.UpSampling2D((16, 16), interpolation=\"bilinear\")(e5)\n",
    "    e5_d1 = conv_block(e5_d1, kernelsize=3, filters=64, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    d1 = layers.Concatenate()([e1_d1, d2_d1, d3_d1, d4_d1, e5_d1])\n",
    "    d1 = conv_block(d1, kernelsize=3, filters=64*5, dropout=dropout, batchnorm=batchnorm)\n",
    "\n",
    "    \"\"\" Final Output \"\"\"\n",
    "    # No deep supervision, just a single output\n",
    "    y1 = layers.Conv2D(num_classes, kernel_size=1, padding=\"same\")(d1)\n",
    "    y1 = layers.Activation(\"sigmoid\")(y1)\n",
    "\n",
    "    outputs = [y1]\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (256, 256, 3)\n",
    "    model = unet3plus(input_shape)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e437e-9c30-4316-b400-355023a7f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1e-15\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2.0 * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8d928-e4b8-41fe-8aff-7005d6b64c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    batch_size = 2\n",
    "    lr = 1e-4\n",
    "    num_epochs = 50\n",
    "    model_path = os.path.join(\"files\", \"model.keras\")\n",
    "    csv_path = os.path.join(\"files\", \"log.csv\")\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = \"Kvasir-SEG\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "\n",
    "    print(f\"Train: \\t{len(train_x)} - {len(train_y)}\")\n",
    "    print(f\"Valid: \\t{len(valid_x)} - {len(valid_y)}\")\n",
    "    print(f\"Test: \\t{len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = unet3plus((IMG_H, IMG_W, 3))\n",
    "    metrics = [\"acc\", tf.keras.metrics.Recall(), tf.keras.metrics.Precision(), dice_coef]\n",
    "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=metrics)\n",
    "\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-10, verbose=1),\n",
    "        CSVLogger(csv_path),\n",
    "        TensorBoard(),\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=valid_dataset,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=1000,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d708b-971a-4824-8b1c-84da487c4ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (IMG_W, IMG_H))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    x = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (IMG_W, IMG_H))\n",
    "    x = x / 255.0\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    x = np.concatenate([x, x, x], axis=-1)\n",
    "    return x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(f\"results\")\n",
    "\n",
    "    \"\"\" Load the model \"\"\"\n",
    "    model_path = os.path.join(\"files\", \"model.keras\")\n",
    "    model = tf.keras.models.load_model(model_path, custom_objects={\"dice_loss\": dice_loss, \"dice_coef\": dice_coef})\n",
    "\n",
    "    \"\"\" Dataset \"\"\"\n",
    "    dataset_path = \"/content/drive/MyDrive/kvasir-seg/Kvasir-SEG\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "\n",
    "    print(f\"Train: \\t{len(train_x)} - {len(train_y)}\")\n",
    "    print(f\"Valid: \\t{len(valid_x)} - {len(valid_y)}\")\n",
    "    print(f\"Test: \\t{len(test_x)} - {len(test_y)}\")\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
    "        \"\"\" Extracting the name \"\"\"\n",
    "        name = x.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Reading the image \"\"\"\n",
    "        x = read_image(x)\n",
    "\n",
    "        \"\"\" Reading the mask \"\"\"\n",
    "        y = read_mask(y)\n",
    "\n",
    "        \"\"\" Prediction \"\"\"\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        pred = model.predict(x, verbose=0)[0]\n",
    "        pred = np.concatenate([pred, pred, pred], axis=-1)\n",
    "        # pred = (pred > 0.5).astype(np.int32)\n",
    "\n",
    "        \"\"\" Save final mask \"\"\"\n",
    "        line = np.ones((IMG_H, 10, 3)) * 255\n",
    "        cat_images = np.concatenate([x[0], line, y*255, line, pred*255], axis=1)\n",
    "        save_image_path = os.path.join(\"results\",  f\"{name}.jpg\")\n",
    "        cv2.imwrite(save_image_path, cat_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Project)",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
